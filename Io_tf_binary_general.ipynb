{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.13/03\n"
     ]
    }
   ],
   "source": [
    "import read_tree as rt\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ten nowy bedzie uproszczony\n",
    "__init__(nazwa_folderu,tryb,co_ile_flush_file=10)\n",
    "    inputs:\n",
    "            nazwa_folderu np \"pierwszy_dataset\" tam bedzie pisac/stamtad bedzie sczytywac. \n",
    "            tryb np 'r' lub 'w' i oznacza czy czytac chcesz czy pisac\n",
    "            co_ile_flush_file to znaczy jak czesto ma oprozniac swoj buffer, liczy sie tylko\n",
    "                    gdy tryb=='w', nie wiem ile ma wynosic,wiec jak wiesz to smialo ustaw\n",
    "\n",
    "write(legs,jets,global_params,properties,l)\n",
    "        dostepna tylko jak tryb to jest 'w'\n",
    "            legs,jets,global_params,properties jak w wyjsciu klasy read_tree, tylko \"dla jednego przypadku\"\n",
    "                wiec jest tak\n",
    "                        zakladam, ze legs to jest lista o shapie (?,4) wypelniona floatami\n",
    "                        jets dokladnie tak samo\n",
    "                        global_params to jest w postaci {nazwa:liczba, ...}\n",
    "                        properties tak samo\n",
    "                        l to label jest intem rownym to 0 lub 1, gdzie 1 oznacza, ze to jest raczej bardziej ciekawy przypadek\n",
    "                         a 0 to taki bardziej tlo. to jest int \n",
    "\n",
    "close()\n",
    "            dostepna tylko dla tryb=='w'\n",
    "            zamyka bezpiecznie nasz plik\n",
    "read()\n",
    "            dostepna tylko dla tryb=='r'\n",
    "            wyrzuci z siebie tensorflowowy dataset gotowy do uczenia\n",
    "                w przyszlosci read moze przeprowadzac dodawanie nowych featcherkow,ale na razie\n",
    "                tego nie robi. W sumie jak mamy dataset to mozemy tez te featcherki nowe dorobic poxniej.\n",
    "                zobaczymy jak to bedzie.\n",
    "            dataset wyglada tak, ze pojedynczy przypadek to jest (slownik_featurow,label)\n",
    "                gdzie label to bedzie 0 lub 1\n",
    "                zas slownik featerow to jest tak, ze sa klucze stringow a wartosci to jest\n",
    "                1d arraye ktore sa intami lub floatami \n",
    "                to znaczy, ze zwraca to samo co ta stara moja klasa czytajaca\n",
    "types()\n",
    "            uzywamy takiego czegos tylko dla type=='r'\n",
    "            zwraca slownik typow naszego datasetu\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "przyjmuje w konstruktorze nazwe folderu gddzie bedzie pisac (utworzy go jak go nie ma)\n",
    "(przyjmujemy zasade jeden zbior danych w jednym folderze, a nazwa folderu jest informatywna)\n",
    "\n",
    "oraz tryb 'r' do czytania 'w' do pisania\n",
    "\n",
    "copy buffer\n",
    "self.iotf_stary=Io_tf_binary_general.Io_tf_binary_stary(\n",
    "            self.nazwa_folderu+\"/dane\",slownik,tryb,co_ile_flush_file)\n",
    "            \n",
    "w funcji  write w argumentach zakladam\n",
    "#zakladam, ze legs to jest lista o shapie (?,4) wypelniona floatami\n",
    "#jets dokladnie tak samo\n",
    "#global_params to jest w postaci {nazwa:liczba, ...}\n",
    "#properties tak samo\n",
    "#l jest intem rownym to 0 lub 1, gdzie 1 oznacza, ze to jest raczej bardziej ciekawy przypadek\n",
    "# a 0 to taki bardziej tlo\n",
    "\n",
    "jest tez funkcja close ktora odcina nas od pliku zapisywanego\n",
    "\n",
    "funkcja read na razie nie bierze argumentow, ale w przyszlosci bedzie robic feature engineering\n",
    "to znaczy dorobi jakies z tych podstawowych typow\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Io_tf_binary_general:\n",
    "    def __init__(self,nazwa_folderu,tryb,co_ile_flush_file=10):\n",
    "        \n",
    "        self.nazwa_folderu=nazwa_folderu\n",
    "        self.tryb=tryb\n",
    "        self.co_ile=co_ile_flush_file\n",
    "        self.nowopowstala=True\n",
    "        \n",
    "    \n",
    "    def zapisz_json(co,gdzie):\n",
    "        f=open(gdzie,'w')\n",
    "        f.write(json.dumps(co))\n",
    "    def wczytaj_json(skad):\n",
    "        f=open(skad,'r')\n",
    "        return json.loads(f.read())\n",
    "    \n",
    "    def zrob_slownik_typow(legs,jets,global_params,properties):\n",
    "        #zakladam, ze legs to jest lista o shapie (?,4) wypelniona floatami\n",
    "        #jets dokladnie tak samo\n",
    "        #global_params to jest w postaci {nazwa:liczba, ...}\n",
    "        wyrzut={}\n",
    "        legs=np.array(legs)\n",
    "        jets=np.array(jets)\n",
    "        n_legs=legs.shape[0]\n",
    "        n_jets=jets.shape[0]\n",
    "        def czy_int(x):\n",
    "            type(x)==int or type(x)==int ==numpy.int64\n",
    "\n",
    "        for i in range(n_legs):\n",
    "            wyrzut[\"leg_\"+str(i)+\"_momentum\"]=(4,'f')\n",
    "        for i in range(n_jets):\n",
    "            wyrzut[\"jet_\"+str(i)+\"_momentum\"]=(4,'f')\n",
    "        def dorob(wyrzut,global_params):\n",
    "            for param_key in global_params.keys():\n",
    "                if np.issubdtype(type(global_params[param_key]), np.integer):\n",
    "                    wyrzut[param_key]=(1,'i')\n",
    "                else:\n",
    "                    wyrzut[param_key]=(1,'f')\n",
    "            return wyrzut\n",
    "        wyrzut=dorob(wyrzut,global_params)\n",
    "        wyrzut=dorob(wyrzut,properties)\n",
    "        return wyrzut\n",
    "    \n",
    "    def zrob_sensowna_forme(legs,jets,global_params,properties,l):\n",
    "        #l jest intem i to 0 lub 1\n",
    "        legs=np.array(legs)\n",
    "        jets=np.array(jets)\n",
    "        n_legs=legs.shape[0]\n",
    "        n_jets=jets.shape[0]\n",
    "\n",
    "        f={}\n",
    "\n",
    "\n",
    "        for i in range(n_legs):\n",
    "            f[\"leg_\"+str(i)+\"_momentum\"]=legs[i,:]\n",
    "        for i in range(n_jets):\n",
    "            f[\"jet_\"+str(i)+\"_momentum\"]=jets[i,:]\n",
    "\n",
    "        for param_key in global_params.keys():\n",
    "            f[param_key]=[global_params[param_key]]\n",
    "        for k in properties:\n",
    "            f[k]=[properties[k]]\n",
    "        return f,l\n",
    "    \n",
    "    def write(self,legs,jets,global_params,properties,l):\n",
    "        #zakladam, ze legs to jest lista o shapie (?,4) wypelniona floatami\n",
    "        #jets dokladnie tak samo\n",
    "        #global_params to jest w postaci {nazwa:liczba, ...}\n",
    "        #l jest intem i to 0 lub 1\n",
    "        assert self.tryb=='w'\n",
    "        if self.nowopowstala==True:\n",
    "            os.system(\"mkdir \"+self.nazwa_folderu)\n",
    "            self.nowopowstala=False\n",
    "            slownik= Io_tf_binary_general.zrob_slownik_typow(legs,jets,global_params,properties)\n",
    "            Io_tf_binary_general.zapisz_json(slownik,self.nazwa_folderu+\"/metadata\")\n",
    "            self.stary_io=Io_tf_binary_general.Io_tf_binary_stary(\n",
    "                self.nazwa_folderu+\"/dane\",slownik,self.tryb,self.co_ile)\n",
    "        f,l=Io_tf_binary_general.zrob_sensowna_forme(legs,jets,global_params,properties,l)\n",
    "        self.stary_io.wpisz(f,l)\n",
    "    def close(self):\n",
    "        assert self.tryb=='w'\n",
    "        if not self.nowopowstala:\n",
    "            self.stary_io.close()\n",
    "    def read(self):\n",
    "        assert self.tryb=='r'\n",
    "        slownik=Io_tf_binary_general.wczytaj_json(self.nazwa_folderu+\"/metadata\")\n",
    "        stary_io=Io_tf_binary_general.Io_tf_binary_stary(\n",
    "                self.nazwa_folderu+\"/dane\",slownik,self.tryb,self.co_ile)\n",
    "        return stary_io.wczytaj_dataset()\n",
    "    def types(self):\n",
    "        assert self.tryb=='r'\n",
    "        return Io_tf_binary_general.wczytaj_json(self.nazwa_folderu+\"/metadata\")\n",
    "    \n",
    "    #jakby ktos kopiowal to to idzie dalej\n",
    "    #==========================================================    \n",
    "        \"\"\"\n",
    "    do creatora dajemy sobie nazwe pliku (sciezke) oraz slownik typu {'czterowektor': (4,'f'),'intowa_wlasnosc': (1,'i'),\n",
    "    ...}\n",
    "    to znaczy nazwe, ile to jest liczb, jakiego typu. Obsluguje na razie jedynie 'f' oraz 'i' to \n",
    "    jest float oraz int\n",
    "    nie mozna uzyc jako klucz 'label', bo to jest wykorzystywana nazwa.\n",
    "\n",
    "\n",
    "    funkcja wpisz bierze jako argument jeden przypadek  cos typu \n",
    "    ({\"czterowektor\":[1.,2.,3.,4.], ...},1) gdzie 1 jest labelem, label jest intem.\n",
    "    . oczywiście klucze slownika zgadzają się \n",
    "    z kluczami ze slownika ktorego uzylismy do kreatora.\n",
    "\n",
    "    dataset wczytany metoda wczytaj dataset jest juz w postaci wygodnej dla mnie to znaczy \n",
    "    slownik feature, label\n",
    "    \"\"\"\n",
    "    class Io_tf_binary_stary:\n",
    "        def __init__(self,nazwa_pliku,slownik,tryb,co_ile_flush_file=10):\n",
    "            #tryb to 'w' dla write oraz 'r' dla read\n",
    "            self.co_ile=co_ile_flush_file\n",
    "            self.plik=nazwa_pliku\n",
    "            self.typy=slownik\n",
    "            for k in self.typy.keys():\n",
    "                assert self.typy[k][1] in ['f','i']\n",
    "                assert self.typy[k][0]>0 \n",
    "                assert np.issubdtype(type(self.typy[k][0]), np.integer)\n",
    "            if tryb=='w':\n",
    "                self.writer= tf.python_io.TFRecordWriter(self.plik)\n",
    "            self.liczba_wrzuconych=0\n",
    "\n",
    "            #self.cos=Io_tf_binary.wrap_int64([5])\n",
    "\n",
    "        def close(self):\n",
    "            self.writer.close()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        To moze sobie czytac ktos kto chce zmieniac wnetrznosci tej klasy\n",
    "        Nie polecam\n",
    "\n",
    "        Teraz ta funkcja wpisz jest ważna. ona bierze po jednym przypadku testowym, \n",
    "        ( to jest ta petla for i in range()) i go zapisuje. trzeba zwracac \n",
    "        uwage na to jakiego typu sa zapisywane rzeczy. mozna oczywiscie zrobic slownik\n",
    "        data dluzszym, jesli to w jakis sposob ulatwi nam myslenie o naszych danych. \n",
    "        Bo te nasze dane to bedzie slownik list, w ktorych to listach rzeczy maja \n",
    "        juz taki sam typ, a klucze to beda jakies opisowe nazwy.\n",
    "        np \n",
    "\n",
    "        data={\n",
    "        'czteroped_lewej_nogi_czy_cos': wrap_float64(cztero), # gdzie cztero to jest tensor floatow o shape (4,)\n",
    "        # reszta rzeczy\n",
    "\n",
    "        }\n",
    "\n",
    "        Jak byscie chcieli jako wartosci miec stringi to musicie pomyslec jak zrobic wrapy dla stringow. oczywiscie\n",
    "        nie znajdziecie zadnej dokumentacji.\n",
    "\n",
    "        UWAGA \n",
    "        w tym slowniku data musi byc to co klasyfikujemy oznaczone przy pomocy 'label' bo inaczej sie  wywali program.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        def wpisz(self,features,label):\n",
    "            \"\"\"tworzy ten nasz dataset w pliku out_path \n",
    "            tu format jest taki jak byl na poczatku to znaczy taki slownik\"\"\"\n",
    "            f=features\n",
    "            l=label\n",
    "            def wrap_int64(value):\n",
    "                \"\"\"lista intow musi wlesc\"\"\"\n",
    "                return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "            def wrap_float64(value):\n",
    "                \"\"\"lista floatow musi wlesc\"\"\"\n",
    "                return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "            #f,l=kolko_w_kolku() #mozna zmienic jak sie podoba\n",
    "            def data_slownik(f,l):\n",
    "                wyrzut={}\n",
    "                for k in self.typy.keys():\n",
    "                    if self.typy[k][1]=='f':\n",
    "                        wyrzut[k]=wrap_float64(np.array(f[k]).reshape((-1,)))\n",
    "                    else:\n",
    "                        wyrzut[k]=wrap_int64(np.array(f[k]).reshape((-1,)))\n",
    "                wyrzut['label']=wrap_int64([l])\n",
    "                return wyrzut\n",
    "\n",
    "\n",
    "\n",
    "            #feature=f[i]\n",
    "            #label=l[i]\n",
    "            #data = {\n",
    "             #    'feature': wrap_float64(feature),\n",
    "            #  'label': wrap_int64([label])\n",
    "               #     }\n",
    "            data=data_slownik(f,l)\n",
    "            # Wrap the data as TensorFlow Features.\n",
    "            feature = tf.train.Features(feature=data)\n",
    "\n",
    "            # Wrap again as a TensorFlow Example.\n",
    "            example = tf.train.Example(features=feature)\n",
    "\n",
    "            # Serialize the data.\n",
    "            serialized = example.SerializeToString()\n",
    "\n",
    "            # Write the serialized data to the TFRecords file.\n",
    "            self.writer.write(serialized)\n",
    "            self.liczba_wrzuconych+=1\n",
    "            if self.liczba_wrzuconych%self.co_ile==0:\n",
    "                self.writer.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        def wczytaj_dataset(self):\n",
    "\n",
    "            def zeslownikoj(x):\n",
    "                keys=list(x.keys())\n",
    "                f={}\n",
    "                for k in keys:\n",
    "                    if not k=='label':\n",
    "                        f[k]=x[k]\n",
    "                return f,x['label']\n",
    "            def features_generoj():\n",
    "                wyrzut={}\n",
    "                for k in self.typy.keys():\n",
    "                    if self.typy[k][1]=='f':\n",
    "                        wyrzut[k]=tf.FixedLenFeature([self.typy[k][0]], tf.float32)\n",
    "                    else:\n",
    "                        wyrzut[k]=tf.FixedLenFeature([self.typy[k][0]], tf.int64)\n",
    "                wyrzut['label']=tf.FixedLenFeature([], tf.int64)\n",
    "                return wyrzut\n",
    "\n",
    "            def parse(serialized):\n",
    "\n",
    "                # Define a dict with the data-names and types we expect to\n",
    "                # find in the TFRecords file.\n",
    "                # It is a bit awkward that this needs to be specified again,\n",
    "                # because it could have been written in the header of the\n",
    "                # TFRecords file instead.\n",
    "                \"\"\"\n",
    "                features = \\\n",
    "                    {\n",
    "                        'dwuwektor': tf.FixedLenFeature([2], tf.float32),#z jakiegos powodu to jest float32, nie wiem czemu\n",
    "                        'label': tf.FixedLenFeature([], tf.int64)\n",
    "                    }\n",
    "                \"\"\"\n",
    "                features=features_generoj()\n",
    "                print(features)\n",
    "\n",
    "                # Parse the serialized data so we get a dict with our data.\n",
    "                parsed_example = tf.parse_single_example(serialized=serialized,\n",
    "                                                         features=features)\n",
    "\n",
    "\n",
    "                return zeslownikoj(parsed_example)\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset(self.plik)\n",
    "            dataset = dataset.map(parse)\n",
    "            return dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ML]\tOpening root file for python conversion.\n",
      "[ML]\tReading data from TTree.\n",
      "[ML]\tConversion to python successful!\n"
     ]
    }
   ],
   "source": [
    "in_file=\"data/dummy.root\"\n",
    "out_file=\"output/example\"\n",
    "tree_path=\"Summary/tree\"\n",
    "legs, jets, global_params, properties = rt.read_tree(in_file, tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(legs).shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wybierz(slownik,i):\n",
    "    wyrzut={}\n",
    "    for k in slownik.keys():\n",
    "        wyrzut[k]=slownik[k][i]\n",
    "    return wyrzut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poczatek przykladu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisacz=Io_tf_binary_general(\"pierwszy\",'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘pierwszy’: File exists\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.array(legs).shape[2]):\n",
    "    pisacz.write(np.array(legs)[:,:,i],np.array(jets)[:,:,i],wybierz(global_params,i),wybierz(properties,i),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisacz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "czytacz=Io_tf_binary_general(\"pierwszy\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leg_0_momentum': FixedLenFeature(shape=[4], dtype=tf.float32, default_value=None), 'leg_1_momentum': FixedLenFeature(shape=[4], dtype=tf.float32, default_value=None), 'jet_0_momentum': FixedLenFeature(shape=[4], dtype=tf.float32, default_value=None), 'jet_1_momentum': FixedLenFeature(shape=[4], dtype=tf.float32, default_value=None), 'BJetBetaScore': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'higgsMassTrans': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'higgsPT': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'nJets30': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'visMass': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_1_charge': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_1_combreliso': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_2_byCombinedIsolationDeltaBetaCorrRaw3Hits': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_2_byIsolationMVArun2v1DBoldDMwLTraw': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_2_charge': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'leg_2_decayMode': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n"
     ]
    }
   ],
   "source": [
    "dataset=czytacz.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leg_0_momentum': [4, 'f'],\n",
       " 'leg_1_momentum': [4, 'f'],\n",
       " 'jet_0_momentum': [4, 'f'],\n",
       " 'jet_1_momentum': [4, 'f'],\n",
       " 'BJetBetaScore': [1, 'f'],\n",
       " 'higgsMassTrans': [1, 'f'],\n",
       " 'higgsPT': [1, 'f'],\n",
       " 'nJets30': [1, 'f'],\n",
       " 'visMass': [1, 'f'],\n",
       " 'leg_1_charge': [1, 'f'],\n",
       " 'leg_1_combreliso': [1, 'f'],\n",
       " 'leg_2_byCombinedIsolationDeltaBetaCorrRaw3Hits': [1, 'f'],\n",
       " 'leg_2_byIsolationMVArun2v1DBoldDMwLTraw': [1, 'f'],\n",
       " 'leg_2_charge': [1, 'f'],\n",
       " 'leg_2_decayMode': [1, 'f']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "czytacz.types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'BJetBetaScore': array([[-999.],\n",
      "       [-999.]], dtype=float32), 'higgsMassTrans': array([[101.59774],\n",
      "       [ 92.35652]], dtype=float32), 'higgsPT': array([[28.415644],\n",
      "       [40.926834]], dtype=float32), 'jet_0_momentum': array([[ 606.46423  ,   -2.0735188,  -28.639431 , -605.7476   ],\n",
      "       [   0.       ,    0.       ,    0.       ,    0.       ]],\n",
      "      dtype=float32), 'jet_1_momentum': array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]], dtype=float32), 'leg_0_momentum': array([[ 55.597507,  39.645374, -32.87137 ,  20.94729 ],\n",
      "       [ 36.391502,  29.55554 , -19.151098,  -9.167096]], dtype=float32), 'leg_1_charge': array([[-1.],\n",
      "       [-1.]], dtype=float32), 'leg_1_combreliso': array([[0.02248299],\n",
      "       [0.02248375]], dtype=float32), 'leg_1_momentum': array([[ 40.830276  , -34.75293   ,   5.0724854 , -20.82296   ],\n",
      "       [ 32.664463  ,  24.164114  ,  -0.59195006, -21.960882  ]],\n",
      "      dtype=float32), 'leg_2_byCombinedIsolationDeltaBetaCorrRaw3Hits': array([[1.5285704],\n",
      "       [0.       ]], dtype=float32), 'leg_2_byIsolationMVArun2v1DBoldDMwLTraw': array([[0.9141986 ],\n",
      "       [0.87725174]], dtype=float32), 'leg_2_charge': array([[1.],\n",
      "       [1.]], dtype=float32), 'leg_2_decayMode': array([[0.],\n",
      "       [1.]], dtype=float32), 'nJets30': array([[1.],\n",
      "       [1.]], dtype=float32), 'visMass': array([[92.204056],\n",
      "       [22.8951  ]], dtype=float32)}, array([0, 0]))\n",
      "({'BJetBetaScore': array([[-9.990000e+02],\n",
      "       [ 9.844911e-01]], dtype=float32), 'higgsMassTrans': array([[47.516647],\n",
      "       [50.974056]], dtype=float32), 'higgsPT': array([[18.746702],\n",
      "       [91.93916 ]], dtype=float32), 'jet_0_momentum': array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]], dtype=float32), 'jet_1_momentum': array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]], dtype=float32), 'leg_0_momentum': array([[  56.707108,  -16.002151,   24.598066,   48.52372 ],\n",
      "       [ 400.52917 ,   17.627192, -101.99386 ,  386.92395 ]],\n",
      "      dtype=float32), 'leg_1_charge': array([[-1.],\n",
      "       [-1.]], dtype=float32), 'leg_1_combreliso': array([[0.16048776],\n",
      "       [0.        ]], dtype=float32), 'leg_1_momentum': array([[ 28.121727 ,   8.6917305, -26.19098  ,  -5.356122 ],\n",
      "       [ 40.224392 ,  11.0102   ,  17.25154  , -34.622578 ]],\n",
      "      dtype=float32), 'leg_2_byCombinedIsolationDeltaBetaCorrRaw3Hits': array([[1.5896997],\n",
      "       [0.       ]], dtype=float32), 'leg_2_byIsolationMVArun2v1DBoldDMwLTraw': array([[0.94189495],\n",
      "       [0.9750222 ]], dtype=float32), 'leg_2_charge': array([[1.],\n",
      "       [1.]], dtype=float32), 'leg_2_decayMode': array([[1.],\n",
      "       [1.]], dtype=float32), 'nJets30': array([[1.],\n",
      "       [1.]], dtype=float32), 'visMass': array([[ 72.639595],\n",
      "       [249.29117 ]], dtype=float32)}, array([0, 0]))\n",
      "({'BJetBetaScore': array([[-999.],\n",
      "       [-999.]], dtype=float32), 'higgsMassTrans': array([[64.59896 ],\n",
      "       [62.368977]], dtype=float32), 'higgsPT': array([[ 68.05407],\n",
      "       [132.27995]], dtype=float32), 'jet_0_momentum': array([[ 249.09726 ,   13.946529,  -17.39489 , -248.02477 ],\n",
      "       [  64.98146 ,   55.21633 ,  -16.537188,   27.998388]],\n",
      "      dtype=float32), 'jet_1_momentum': array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]], dtype=float32), 'leg_0_momentum': array([[200.1238   , -14.138713 , -39.307823 , 195.7154   ],\n",
      "       [ 32.924274 ,   4.7681417,  20.6016   , -25.235601 ]],\n",
      "      dtype=float32), 'leg_1_charge': array([[1.],\n",
      "       [1.]], dtype=float32), 'leg_1_combreliso': array([[0.14260158],\n",
      "       [0.        ]], dtype=float32), 'leg_1_momentum': array([[ 220.03221 ,   28.186718,   35.217102, -215.35846 ],\n",
      "       [ 496.81525 ,  -41.740227,  -93.2722  , -486.1928  ]],\n",
      "      dtype=float32), 'leg_2_byCombinedIsolationDeltaBetaCorrRaw3Hits': array([[0.],\n",
      "       [0.]], dtype=float32), 'leg_2_byIsolationMVArun2v1DBoldDMwLTraw': array([[0.96189445],\n",
      "       [0.8895842 ]], dtype=float32), 'leg_2_charge': array([[1.],\n",
      "       [1.]], dtype=float32), 'leg_2_decayMode': array([[1.],\n",
      "       [0.]], dtype=float32), 'nJets30': array([[2.],\n",
      "       [2.]], dtype=float32), 'visMass': array([[419.44147],\n",
      "       [111.43169]], dtype=float32)}, array([0, 0]))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=2\n",
    "zbachowany=dataset.shuffle(1000).repeat().batch(BATCH_SIZE)\n",
    "iterator = zbachowany.make_one_shot_iterator()\n",
    "para=iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        print(sess.run(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
