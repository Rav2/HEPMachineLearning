{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#teraz sproboje z tego zrobic jakis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f,l=kolko_w_kolku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((f,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE=100\n",
    "#zbachowany=dataset.shuffle(1000).repeat().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to jest dataset zaraz zastanowie sie jak go zapisac do pliku i z tego pliku odczytac a teraz jak go czytac?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterator = zbachowany.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f,l=iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "#    for i in range(100):\n",
    "#        sess.run(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap_float64([5.55,6.85]) #swietnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Podajemy slownik na takich samych zasadach co podawalismy do tamtego Io_tf_binary\n",
    "Tym razem jak podajemy sciezke do pliku to ten plik ma juz byc pelen danych. \n",
    "\n",
    "Na razie w pierwszym rzucie nie bedzie jeszcze danych typu kategorycznego.\n",
    "\n",
    "To ma byc kompatybilne z klasa Io_tf_binary_general\n",
    "\n",
    "__init__(nazwa_folderu,hidden_units,model_dir)\n",
    "        to jest nazwa_folderu odnosi sie do folderu w ktorym pisala klasa\n",
    "        Io_tf_binary_general czy cos\n",
    "        hidden_units to jest lista po ile ma byc ukrytych unitsow. czyli nie podajemy rozmiaru\n",
    "        danych wejsciowych ani wyjsciowych. idziemy od pierwszej (najblizszej inputu) do ostatniej\n",
    "        model_dir to tam bedzie pisac swoje rzeczy nasz model\n",
    "train \n",
    "        jest self explainatory. wydaje mi sie, ze to robi tak, ze kontynuuje trenowanie z miejsca w ktorym skonczylo\n",
    "evaluate \n",
    "        to jest zwykla ewaluacja. tyle, ze mozna podac jako argument \"folder\" z ktorego pochodza\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import Io_tf_binary_general as io\n",
    "\n",
    "\n",
    "class Dnn_uniwersalny:\n",
    "    def __init__(self,nazwa_folderu,hidden_units,model_dir):\n",
    "        self.model_dit=model_dir\n",
    "        self.nazwa_folderu=nazwa_folderu\n",
    "        self.hidden_units=hidden_units\n",
    "        self.wczytywacz=io.Io_tf_binary_general(nazwa_folderu,'r')\n",
    "        self.typy=self.wczytywacz.types()\n",
    "        my_feature_columns = []\n",
    "        for k in self.typy.keys():\n",
    "            if self.typy[k][1]=='f':\n",
    "                t=tf.float32\n",
    "            else:\n",
    "                t=tf.int32\n",
    "            my_feature_columns.append(tf.feature_column.numeric_column(key=k,shape=\\\n",
    "                        (self.typy[k][0],),dtype=t ))\n",
    "        \n",
    "        self.feature_columns=my_feature_columns\n",
    "        \n",
    "        def input_fn( batch_size=100,buffer_size=1000,folder=nazwa_folderu,one_epoch=False):\n",
    "            \"\"\"input function for training\n",
    "            nazwy to lista nazw feature w kolejnosci wystepowania\n",
    "            if one_epoch to tylko jedna epoka\"\"\"\n",
    "            dataset=io.Io_tf_binary_general(folder,'r').read()\n",
    "            if one_epoch:\n",
    "                return dataset.shuffle(buffer_size).repeat(1).batch(batch_size)\n",
    "            return dataset.shuffle(buffer_size).repeat().batch(batch_size)\n",
    "        self.input_fn=input_fn\n",
    "        \n",
    "        self.classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=self.feature_columns,\n",
    "        hidden_units=self.hidden_units,\n",
    "        model_dir=model_dir,\n",
    "        n_classes=2)\n",
    "    def train(self,batch_size=128,buffer_size=1000,steps=3000):\n",
    "        self.classifier.train(\n",
    "        input_fn=lambda:self.input_fn( batch_size,buffer_size),\n",
    "        steps=steps)\n",
    "    def evaluate(self,batch_size=128,buffer_size=1000,steps=1000,folder=\"\"):\n",
    "        if folder==\"\":\n",
    "            folder=self.nazwa_folderu\n",
    "        self.last_eval_result = self.classifier.evaluate(\n",
    "        input_fn=lambda:self.input_fn( batch_size,buffer_size,folder=folder),\n",
    "        steps=steps)\n",
    "        return self.last_eval_result\n",
    "    def predict(self,batch_size=128,buffer_size=1000,steps=100,folder=\"\"):\n",
    "        if folder==\"\":\n",
    "            folder=self.nazwa_folderu\n",
    "        return self.classifier.predict(input_fn=\n",
    "           lambda:self.input_fn(batch_size,buffer_size,folder=folder,one_epoch=True)\n",
    "                                      )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ta linijka zaklada, ze zrobilismy plik dane_treningowe2 wedlug Io_tf_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'weak_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa64d861748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model=Dnn_uniwersalny('weak_train',[10],\"weak_estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from weak_estimator/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into weak_estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 83.917694, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 180.05\n",
      "INFO:tensorflow:loss = 84.96225, step = 12101 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.748\n",
      "INFO:tensorflow:loss = 86.89224, step = 12201 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.805\n",
      "INFO:tensorflow:loss = 85.49861, step = 12301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.412\n",
      "INFO:tensorflow:loss = 86.97571, step = 12401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.132\n",
      "INFO:tensorflow:loss = 87.76213, step = 12501 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.796\n",
      "INFO:tensorflow:loss = 86.09338, step = 12601 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.477\n",
      "INFO:tensorflow:loss = 83.463425, step = 12701 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.33\n",
      "INFO:tensorflow:loss = 85.18864, step = 12801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.413\n",
      "INFO:tensorflow:loss = 83.95096, step = 12901 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.045\n",
      "INFO:tensorflow:loss = 86.63264, step = 13001 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.853\n",
      "INFO:tensorflow:loss = 82.644966, step = 13101 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.123\n",
      "INFO:tensorflow:loss = 83.45581, step = 13201 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.766\n",
      "INFO:tensorflow:loss = 85.5787, step = 13301 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.017\n",
      "INFO:tensorflow:loss = 88.494156, step = 13401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.757\n",
      "INFO:tensorflow:loss = 86.9616, step = 13501 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.443\n",
      "INFO:tensorflow:loss = 90.11386, step = 13601 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.044\n",
      "INFO:tensorflow:loss = 84.0325, step = 13701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.227\n",
      "INFO:tensorflow:loss = 83.88314, step = 13801 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.346\n",
      "INFO:tensorflow:loss = 85.05003, step = 13901 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.076\n",
      "INFO:tensorflow:loss = 80.80408, step = 14001 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.4\n",
      "INFO:tensorflow:loss = 85.778336, step = 14101 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.149\n",
      "INFO:tensorflow:loss = 85.324295, step = 14201 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.644\n",
      "INFO:tensorflow:loss = 87.05655, step = 14301 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.055\n",
      "INFO:tensorflow:loss = 82.41258, step = 14401 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.834\n",
      "INFO:tensorflow:loss = 85.92254, step = 14501 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.357\n",
      "INFO:tensorflow:loss = 82.69629, step = 14601 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.397\n",
      "INFO:tensorflow:loss = 84.87764, step = 14701 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.437\n",
      "INFO:tensorflow:loss = 83.28259, step = 14801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.759\n",
      "INFO:tensorflow:loss = 87.80927, step = 14901 (0.527 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into weak_estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 88.132484.\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-13-14:03:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from weak_estimator/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-13-14:03:47\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.6034922, accuracy_baseline = 0.503125, auc = 0.623732, auc_precision_recall = 0.5975759, average_loss = 0.6665344, global_step = 9000, label/mean = 0.503125, loss = 85.31641, precision = 0.58476716, prediction/mean = 0.5062775, recall = 0.7309317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6034922,\n",
       " 'accuracy_baseline': 0.503125,\n",
       " 'auc': 0.623732,\n",
       " 'auc_precision_recall': 0.5975759,\n",
       " 'average_loss': 0.6665344,\n",
       " 'label/mean': 0.503125,\n",
       " 'loss': 85.31641,\n",
       " 'precision': 0.58476716,\n",
       " 'prediction/mean': 0.5062775,\n",
       " 'recall': 0.7309317,\n",
       " 'global_step': 9000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-13-14:04:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from weak_estimator/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-13-14:04:39\n",
      "INFO:tensorflow:Saving dict for global step 9000: accuracy = 0.757, accuracy_baseline = 0.512, auc = 0.8135166, auc_precision_recall = 0.78371024, average_loss = 0.5930999, global_step = 9000, label/mean = 0.512, loss = 75.91679, precision = 0.7152, prediction/mean = 0.5070935, recall = 0.8730469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.757,\n",
       " 'accuracy_baseline': 0.512,\n",
       " 'auc': 0.8135166,\n",
       " 'auc_precision_recall': 0.78371024,\n",
       " 'average_loss': 0.5930999,\n",
       " 'label/mean': 0.512,\n",
       " 'loss': 75.91679,\n",
       " 'precision': 0.7152,\n",
       " 'prediction/mean': 0.5070935,\n",
       " 'recall': 0.8730469,\n",
       " 'global_step': 9000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(folder=\"weak_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiec czegos sie nauczyl ewidentnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7fa64d894b48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from weak_estimator/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logits': array([-1.1164476], dtype=float32),\n",
       " 'logistic': array([0.24667083], dtype=float32),\n",
       " 'probabilities': array([0.75332916, 0.24667081], dtype=float32),\n",
       " 'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': array([0.3045901], dtype=float32), 'logistic': array([0.5755642], dtype=float32), 'probabilities': array([0.42443576, 0.5755642 ], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.38373333], dtype=float32), 'logistic': array([0.59477323], dtype=float32), 'probabilities': array([0.4052268 , 0.59477323], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.29605216], dtype=float32), 'logistic': array([0.57347715], dtype=float32), 'probabilities': array([0.42652285, 0.57347715], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([-0.07647762], dtype=float32), 'logistic': array([0.48088992], dtype=float32), 'probabilities': array([0.5191101 , 0.48088992], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.1226465], dtype=float32), 'logistic': array([0.53062326], dtype=float32), 'probabilities': array([0.46937677, 0.53062326], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.47450304], dtype=float32), 'logistic': array([0.616449], dtype=float32), 'probabilities': array([0.38355097, 0.616449  ], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.32680285], dtype=float32), 'logistic': array([0.58098125], dtype=float32), 'probabilities': array([0.41901875, 0.58098125], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([0.39195594], dtype=float32), 'logistic': array([0.5967535], dtype=float32), 'probabilities': array([0.40324652, 0.5967535 ], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([-0.55873466], dtype=float32), 'logistic': array([0.36384028], dtype=float32), 'probabilities': array([0.6361597, 0.3638403], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object)}\n",
      "\n",
      "\n",
      "{'logits': array([-0.07633278], dtype=float32), 'logistic': array([0.48092604], dtype=float32), 'probabilities': array([0.51907396, 0.4809261 ], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for p in a:\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break\n",
    "    print(p)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
