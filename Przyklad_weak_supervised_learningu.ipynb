{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przyklad weak supervised algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Io_tf_binary_general as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utworze teraz dane jakies\n",
    "#tutaj zachecam do machania tymi domyslnymi wartosciami. Tu niestety tego nie narysowalem, ale \n",
    "# to tworzy takie wlasnie kolko w kolku na plaszczyxnie.\n",
    "def kolko_w_kolku(klasa,sig1=0.4,sig2=0.25,R2=0.8,N=1000):\n",
    "    \"\"\"to ma utworzyc dane ktore posluza mi do sprawdzenia czy i jak dziala model\n",
    "    klasa to 0 lub 1\"\"\"\n",
    "    \n",
    "    if klasa==1:\n",
    "        x=np.random.normal(0,sig1)\n",
    "        y=np.random.normal(0,sig1)\n",
    "        #features.append([x,y])\n",
    "        return {\"pierwsza\":x,\"inna_wlasnosc\":y}\n",
    "    else:\n",
    "        alpha=np.random.uniform()*2*np.pi\n",
    "        delr=np.random.normal(0,sig2)\n",
    "        r=R2+delr\n",
    "        x=np.cos(alpha)*r\n",
    "        y=np.sin(alpha)*r\n",
    "        #features.append([x,y])\n",
    "        return {\"pierwsza\":x,\"inna_wlasnosc\":y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0_train=0.3\n",
    "p1_train=0.7\n",
    "p0_validate=0.2\n",
    "p1_validate=0.8\n",
    "#to pierwse to prawdopodobienstwo, ze cos z pierwszej populacji jest naprawdÄ™ 1\n",
    "# to drugie to prawdopodobiensto, ze cos z drugiej populacji jest naprawde 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tworze datasety ktore odpowiadaja koejno danym treningowym skladajacym sie\\n z labelek takich, ze jak jakas wskazuje 0 to z prawdopodobienstwem 0.3 jednak jest jedynka (rozpadem\\n higgsa), zas jak wskazuje 1 to z prawdopodobienstwem 0.7 jest rzeczywiscie rozpadem. To teraz pisalem o \\n tym datascie \"weak_train\". potem tworze jeszcze weak_validate ktory jest mniejszy ale idea jest taka,\\n ze na weak_validate znamy skad inond te prawdopodobienstwa, a na weak_train nie znamy ich.\\n weak_true tworze tylko po to, by moc sprawdzic, czy policzona auc na danych weak_validate zgodnie\\n z ta praca ktora na poczatku nam przesylal Kalinowski o weak supervised learning zgadza sie\\n z rzeczywistoscia'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tworze datasety ktore odpowiadaja koejno danym treningowym skladajacym sie\n",
    " z labelek takich, ze jak jakas wskazuje 0 to z prawdopodobienstwem 0.3 jednak jest jedynka (rozpadem\n",
    " higgsa), zas jak wskazuje 1 to z prawdopodobienstwem 0.7 jest rzeczywiscie rozpadem. To teraz pisalem o \n",
    " tym datascie \"weak_train\". potem tworze jeszcze weak_validate ktory jest mniejszy ale idea jest taka,\n",
    " ze na weak_validate znamy skad inond te prawdopodobienstwa, a na weak_train nie znamy ich.\n",
    " weak_true tworze tylko po to, by moc sprawdzic, czy policzona auc na danych weak_validate zgodnie\n",
    " z ta praca ktora na poczatku nam przesylal Kalinowski o weak supervised learning zgadza sie\n",
    " z rzeczywistoscia\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisacz=io.Io_tf_binary_general(\"weak_train\",'w')\n",
    "for i in range(10000):\n",
    "    klasa=np.random.randint(0,2)\n",
    "    if klasa==0:\n",
    "        prawdziwa=int(np.random.uniform()<p0_train)\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),0)\n",
    "    else:\n",
    "        prawdziwa=int(np.random.uniform()<p1_train)\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),1)\n",
    "pisacz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisacz=io.Io_tf_binary_general(\"weak_validate\",'w')\n",
    "for i in range(1000):\n",
    "    klasa=np.random.randint(0,2)\n",
    "    if klasa==0:\n",
    "        prawdziwa=int(np.random.uniform()<p0_validate)\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),0)\n",
    "    else:\n",
    "        prawdziwa=int(np.random.uniform()<p1_validate)\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),1)\n",
    "pisacz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pisacz=io.Io_tf_binary_general(\"weak_true\",'w')\n",
    "for i in range(1000):\n",
    "    klasa=np.random.randint(0,2)\n",
    "    if klasa==0:\n",
    "        prawdziwa=klasa\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),0)\n",
    "    else:\n",
    "        prawdziwa=klasa\n",
    "        pisacz.write_old(kolko_w_kolku(prawdziwa),1)\n",
    "pisacz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "({'inna_wlasnosc': array([[0.22005723],\n",
      "       [0.22612055]], dtype=float32), 'pierwsza': array([[-0.6884664 ],\n",
      "       [-0.60397434]], dtype=float32)}, array([0, 0]))\n",
      "({'inna_wlasnosc': array([[-0.7017992 ],\n",
      "       [-0.29339036]], dtype=float32), 'pierwsza': array([[-0.02933752],\n",
      "       [ 0.5992255 ]], dtype=float32)}, array([0, 1]))\n",
      "({'inna_wlasnosc': array([[-0.09941217],\n",
      "       [-0.10785457]], dtype=float32), 'pierwsza': array([[-0.35607988],\n",
      "       [-0.7815257 ]], dtype=float32)}, array([0, 0]))\n"
     ]
    }
   ],
   "source": [
    "czytacz=io.Io_tf_binary_general(\"weak_validate\",'r')\n",
    "dataset=czytacz.read()\n",
    "BATCH_SIZE=2\n",
    "zbachowany=dataset.shuffle(1000).repeat().batch(BATCH_SIZE)\n",
    "iterator = zbachowany.make_one_shot_iterator()\n",
    "para=iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(3):\n",
    "        print(sess.run(para))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import Dnn_uniwersalny as dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierwsza': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'inna_wlasnosc': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'label': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'weak_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f38bbe75eb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model=dnn.Dnn_uniwersalny(\"weak_train\",[10],\"weak_estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dnn_uniwersalny' object has no attribute 'make_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8b5ef0e72a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dnn_uniwersalny' object has no attribute 'make_model'"
     ]
    }
   ],
   "source": [
    "model.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train() #trenujemy na \"weak_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc,xxxx,yyyy,zzz=model.evaluate_jak_z_pracy(0.2,0.8,folder=\"weak_validate\")\n",
    "auc #auc policzona na weak_validate zgodnie z praca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(folder=\"weak_true\")\n",
    "    #auc policzona zgodnie z tym, jak to sie liczy normalnie gdy ma sie dobrze oznaczone dane gdzie\n",
    "    # na pewno byl higgs lub na pewno nie bylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tutaj nalezy zwrocic swoja uwage na to, ze auc policzone na danych co do ktorych wiemy dokladnie czy\n",
    "sa rozpadem czy nie jest podobne do auc policzonego na podstawie labelek co do ktorych znamy tylko prawdopodobienstwo\n",
    "czy sa rozpadem\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
