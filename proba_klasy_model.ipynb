{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import zapisywacz\n",
    "\n",
    "def zapisz_json(co,gdzie):\n",
    "    f=open(gdzie,'w')\n",
    "    f.write(json.dumps(co))\n",
    "\n",
    "def wczytaj_json(skad):\n",
    "    f=open(skad,'r')\n",
    "    return json.loads(f.read())\n",
    "\n",
    "def wyrwij_label(slownik):\n",
    "    l= slownik.pop('l')\n",
    "    return slownik, l\n",
    "\n",
    "def rob_feature_columns(nazwa_zrodla):\n",
    "    kategoryczne_typy = zapisywacz.wczytaj_typy_kategorycznych(nazwa_zrodla)\n",
    "    numeryczne_typy = zapisywacz.wczytaj_typy_numerycznych(nazwa_zrodla)\n",
    "    dlugosc_numerycznych = numeryczne_typy[len(numeryczne_typy) - 1][2]\n",
    "    wyn = []\n",
    "    wyn.append(tf.feature_column.numeric_column(\n",
    "        key = 'n', shape=(dlugosc_numerycznych,)  ))\n",
    "    for kat in kategoryczne_typy:\n",
    "        nowy = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key = kat[0],\n",
    "            vocabulary_list = kat[1],\n",
    "            dtype = tf.int32\n",
    "        )\n",
    "        hot = tf.feature_column.indicator_column(nowy)\n",
    "        wyn.append(hot)\n",
    "    return wyn\n",
    "\n",
    "#nazwa_folderu to jak sie bedzie nazywac folder modelu\n",
    "#glowne_zrodlo_danych to plik z ktorego beda pochodzic dane\n",
    "# do policzenia danych do normalizacji danych\n",
    "def tworz_folder(nazwa_folderu, glowne_zrodlo_danych, hidden_units, na_ilu_statystyki = 10000):\n",
    "    assert not os.path.isdir(nazwa_folderu)\n",
    "    os.mkdir(nazwa_folderu)\n",
    "    def licz_statystyki(nazwa_zrodla, na_ilu):\n",
    "        dataset = zapisywacz.parsuj_i_batchuj(nazwa_zrodla, na_ilu, 1)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        tab = iterator.get_next()['n']\n",
    "        mean, variance = tf.nn.moments(tab, axes=[0])\n",
    "        return mean, variance\n",
    "    \n",
    "    mean, variance = licz_statystyki(glowne_zrodlo_danych, na_ilu_statystyki)\n",
    "    print('policzylo mean oraz variance')\n",
    "    with tf.Session() as sess:\n",
    "        mean, variance = sess.run((mean, variance))\n",
    "        np.savetxt(nazwa_folderu + '/mean', mean)\n",
    "        np.savetxt(nazwa_folderu + '/var',variance)\n",
    "    print('zapisalo je')\n",
    "    feature_columns = rob_feature_columns(glowne_zrodlo_danych)\n",
    "    model = tf.estimator.DNNClassifier(\n",
    "        hidden_units = hidden_units,\n",
    "        feature_columns = feature_columns,\n",
    "        model_dir = nazwa_folderu + '/model',\n",
    "        n_classes = 2\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "\n",
    "def odczytaj_mean_var(nazwa_folderu):\n",
    "    mean = np.loadtxt(nazwa_folderu + '/mean')\n",
    "    var = np.loadtxt(nazwa_folderu + '/var')\n",
    "    return mean, var\n",
    "\n",
    "#odczytujemy juz istniejacy model\n",
    "def wczytaj_model(nazwa_folderu):\n",
    "    assert os.path.isdir(nazwa_folderu + '/model')\n",
    "    return tf.estimator.DNNClassifier(model_dir = nazwa_folderu + '/model')\n",
    "\n",
    "def input_fn(zrodlo_danych, folder_modelu, batch_size,  \n",
    "         czy_shuffle, ile_threadow, czy_repeat, buffer_size,\n",
    "         czy_cache ):\n",
    "    mean, var = odczytaj_mean_var(folder_modelu)\n",
    "    dataset = zapisywacz.parsuj_i_batchuj(zrodlo_danych, batch_size, ile_threadow)\n",
    "    kategoryczne = zapisywacz.wczytaj_typy_kategorycznych(zrodlo_danych)\n",
    "    if(czy_repeat):\n",
    "        dataset = dataset.repeat()\n",
    "    def normalizacja(slownik):\n",
    "        slownik['n'] = (slownik['n'] - mean) / (var**0.5)\n",
    "        return slownik\n",
    "    def odczep_kategoryczne(slownik):\n",
    "        kat_tab = slownik.pop('c')\n",
    "        for i in range(len(kategoryczne)):\n",
    "            slownik[kategoryczne[i][0]] = kat_tab[:, i]\n",
    "        return slownik\n",
    "    dataset = dataset.map(odczep_kategoryczne, num_parallel_calls = ile_threadow)\n",
    "    dataset = dataset.map(normalizacja,num_parallel_calls = ile_threadow)\n",
    "    dataset = dataset.map(wyrwij_label,num_parallel_calls = ile_threadow)\n",
    "    if czy_shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    if czy_cache:\n",
    "        dataset = dataset.cache()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policzylo mean oraz variance\n",
      "zapisalo je\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_probny/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f14a71a2a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tworz_folder('model_probny', 'pierwszy',\n",
    "             [30], na_ilu_statystyki = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = input_fn('pierwszy','model_probny', 10,  \n",
    "         True, 1, True, 10,\n",
    "         True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/anaconda3/envs/root_tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n': array([[-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ],\n",
       "         [-0.04469895, -0.04469948, -0.04469915, -0.04469931, -0.0446989 ]],\n",
       "        dtype=float32), 'c': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])},\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costam = dataset.make_one_shot_iterator()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(costam.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
